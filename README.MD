# **CV-Vector-Quantization**

# 도면 수정 및 변경 추적 파이프라인
본 문서는 '도면 수정 및 변경 추적' 과제에 대한 최종 해결책을  담은 기술 보고서 입니다. 문제 정의부터 최종 구현까지, 모든 의사결정 과정가 그에대한 기술적 근거를 상세히 기록하였습니다. 

## 1. 문제 정의 및 목표

### 문제 상황
건설 현장에서 사용되는 도면은 파일명 규칙이나 스캔 품질이 제각각이며, 빈번한 수정으로 인해 변경 이력을 수동으로 추적하기 어렵다는 문제가 있습니다.

### 목표
`first_upload` 폴더의 원본 도면과 `second_upload` 폴더의 수정된 도면을 비교하여, 다음 두 가지를 해결하는 End-to-End 파이프라인을 구축합니다.


## 2. 실행 방법

### 사전 요구 사항
- Python 3.8 이상
- 필요 라이브러리는 requirements.txt에 명시되어 있습니다.

### 설치 
- `pip install -r requirements.txt`

### 실행
터미널에서 아래와 같은 명령어를 실행합니다.
- `python main.py --v1 ./first_upload --v2 ./second_upload --out ./results`


## 3. 해결 전략 및 설계
**저는 해당 문제를 단순히 도면의 차이점을 찾는 과제가 아닌, 주어진 데이터의 특성에 가장 적합한 기술 스택을 선택하고 그 근거를 증명하는 엔지니어링 문제로 접근을 했습니다.** 

### 3-1. 벡터 양자화를 통한 데이터 복잡도 분석 
![VQ Codebook](https://github.com/RL9-csv/CV-Vector-Quantization/blob/main/assets/vq_codebook.png.png?raw=true)


파이프라인 설계에 앞서, 데이터 자체의 시각적 복잡도를 분석하기 위해 벡터 양자화를 수행했습니다. `K=64`로 설정하여 데이터 셋 전체에서 시각 단어집(Visual Vocabulary)을 학습한 결과, 모델이 학습한 단어들은 '문'이나 '창문' 같은 의미를 담는 객체가 아닌, 수직/수평, 모서리, 공백 등 매우 기본적인 기하학적 패턴으로 구성되어 있음을 확인했습니다.  

**벡터 양자화 결론**: 이는 본 데이터셋의 시작적 복잡도가 낮아, 간단한 기하학적인 조합만으로도 도면의 구조를 충분히 설명할 수 있음을 의미합니다. 따라서 수백만 개의 파라미터로 복잡한 시멘틱을 학습하는 딥러닝 모델은 해당 문제에 대한 오버엔지니어링(Over-engineering)이라는 데이터 기반의 결론을 내렸습니다. 


### 클러색 CV 파이프라인은 다음과 같은 2단계로 구성됩니다.
위의 벡터 양자화 분석을 근거로, 데이터의 특성에 적합하고 효율성과 설명 가능성을 모두 확보할 수 있는 클래식 CV 파이프라인을 해결책으로 채택하였습니다. 파이프라인은 아래와 같은 2단계로 구성됩니다. 

1. **고속 매칭**: `imagehash` 라이브러리의 `Perceptual Hash(pHash)`를 사용하여 이미지의 고유한 특성을 추출하고, 해밍 거리로 이미지 간의 유사성을 측정합니다. 

2. **정밀 탐지**: `OpenCV`의 `ORB`특징점 매칭과 `findHomograpy`를 통해 이미지를 정렬한 이후, `absdiff`와 임계 처리를 통해서 변경점을 시각화 합니다. 


## 4. 핵심 의사결정 및 실험 과정

### 4-1. Ground Truth 재정의: 문제의 진짜 정답 쌍은 4개
초기 탐색 결과, v2 폴더의 6개 파일이 모두 v1 폴더에 짝을 가질 것이라는 가설은 틀렸다는 것을 발견했습니다. 육안 검증과 `pHash`거리 분석을 통해, 아래 두 쌍은 단순 수정본이 아닌 별개 문서임을 확인했습니다. 

- **이상치 I(구조적 변경)**: Cross Section과 Longitudinal Section (`pHash` 거리=24)
- **이상치 II(내용적 차이)**: Door Schedule - 1과 Door Schedule - 2 (`pHash` 거리: 10)

**결론**: 시스템의 성능을 정확하게 평가하기 위한 Ground Truth는 4개의 쌍으로 최종 재정의했습니다.

### 정답지 확정
따라서 두 단명도 쌍을 비정답으로 판정을 했고, 다른 한 쌍은 육안으로 다른 쌍으로 판정을 하고, 최종 실험 결과를 검증할 때 사용하게 될 정답지를 4개의 쌍으로 재정의 했습니다. 

### 4-2. 최적의 임계값 선정 실험

재정의된 4개의 정답 쌍을 기준으로, 매칭 단계의 핵심 파라미터인 `hash_threshold`의 최적값을 찾기 위해 `F1-Score`를 측정했습니다. 

| **Threshold** | **TP** | **FP** | **FN** | **F1-Score** | **비고** |
| :--- | :--- | :--- | :--- | :--- | :--- |
| 5 | 3 | 0 | 1 | 0.8571 | 정답 1개 누락 (FN=1) |
| 6 | 4 | 0 | 0 | 1.0000 | 최적 구간 시작 |
| 7 | 4 | 0 | 0 | 1.0000 | 최적 구간 |
| 8 | 4 | 0 | 0 | 1.0000 | 최적 구간 |
| 9 | 4 | 0 | 0 | 1.0000 | 최적 구간 |
| 10 | 4 | 1 | 0 | 0.8889 | 오탐지 발생 (FP=1) |
| 11 | 4 | 1 | 0 | 0.8889 | 오탐지 발생 (FP=1) |
| 12 | 4 | 1 | 0 | 0.8889 | 오탐지 발생 (FP=1) |

### 4-3. 결론: 최적의 임계값
실험 결과, 임계값이 6에서 9사이일 때 F1-Score 1.0을 달성하며 가장 이상적인 성능을 보였습니다.
- **`threshold < 6`**: {`1904c01649e38bfc79d24b17265fb5e6948c3984c3a4aa0e9969984749ba6026.png`: `4ff0f51c278628c7ed217a37a4d1a70c68aa4b27996c31aad04b0ed11673b677.png`}쌍(거리=6)을 놓치기 시작하며 재현율이 하락합니다. 

- **`threshold > 9`**: {`1904c01649e38bfc79d24b17265fb5e6948c3984c3a4aa0e9969984749ba6026.png`: `b98684714bfdad401c8b0141871f497ab1803316333be7921b32b68ac495db2e.png`}쌍(거리=10, 오답)을 오탐지하기 시작하며 정밀도가 하락합니다. 

특히, `threshold=10`에서 `F1-Score`가 하락하기 시작하는 원인을 분석한 결과, {`1904c01649e38bfc79d24b17265fb5e6948c3984c3a4aa0e9969984749ba6026.png`: `b98684714bfdad401c8b0141871f497ab1803316333be7921b32b68ac495db2e.png`}가 '거리=10'으로 매칭되는 오탐지 케이스를 발견했습니다. 두 문서는 '2*3그리드'라는 동일한 시각적인 구조를 공유하지만, 세부 내용적으로는 각각 '문'과 '창문'이라는 완전히 다른 정보를 담고 있습니다. 이는 `Perceptual Hash`가 내용의 의미가 아닌 이미지 데이터의 전체적인 구조에 더 가중치를 두고 반응하는 알고리즘의 한계를 보여줍니다. 

**최종 임계값 설정**: `threshold=10` 에서 Door Schedule 오탐지가 발생함을 확인, 정밀도를 확보하기 위해 최적 구간(6~9) 내에서 안전 마진을 고려하여 9를 최종 임계값으로 선택했습니다.


### 4-4. 기타 주요 파라미터 설정 근거
주요한 `hash_threshold` 외의 주요 파라미터들은, 알고리즘의 특성과 데이터의 특성을 고려하여 합리적인 기본값으로 설정햇습니다. 

**`n_features=2000 (ORB)`**: 연산량 증가 대비 성능 향상 효과가 미미하기 때문에, 성능과 속도의 균형점인 2000을 기본값으로 설정했습니다.

**`good_match_percent=0.05 (Matcher)`**: 대부분의 잘못된 매칭(Outlier)을 걸러내고 `findHomography`의 안정성을 높이는 검증된 표준 값입니다.

**`min_contour_area=100 (Diff)`**: 100이라는 임계값은 수정된 신호는 보존하면서 스캔 과정에서 발생할 수 있는 10x10 픽셀 미만의 미세한 노이즈는 효과적으로 필터링할 수 있는 합리적인 경계선이라고 판단하여 설정하였습니다. 

## 5. 한계점 분석

![오탐지 예시](./assets/diff_1904c016_vs_4ff0f51c.png)
위의 이미지는 {`1904c01649e38bfc79d24b17265fb5e6948c3984c3a4aa0e9969984749ba6026.png`: `4ff0f51c278628c7ed217a37a4d1a70c68aa4b27996c31aad04b0ed11673b677.png`}쌍의 변경 부분의 표시가 반영이 된 결과 이미지입니다. 하지만 `first_upload`폴더의 이미지와 `second_upload`폴더의 이미지를 비교 분석을 해보면, 실제 변경이 없는 이미지 하단부 까지 변경 영역으로 잘못 탐지하는 오탐지 현상을 발견했습니다. 

**오탐 원인 분석**: 오탐의 원인은 `ORB` 특징점 기반의 정렬 알고리즘이, 특징점이 거의 없는 넓고 비어있는 영역에서 미세한 정렬 오차를 발생시킬 수 있다는 기술적 한계 때문입니다. `adsdiff`는 이 1~2픽셀의 미세한 오차를 실제 변경으로 오인하게 됩니다. 

**해결 방안**: 이러한 정렬 오류를 해결하기 위해서는, OCR을 통해 테이블 내 텍스트 데이터만 비교하거나, 관심 영역(ROI)을 설정하여 특징점이 풍부한 영역에 대해서만 정렬을 수행하는 등, 더 고도화된 접근법이 필요합니다.
